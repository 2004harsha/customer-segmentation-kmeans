# Customer Segmentation with Kâ€‘Means (RFM)

This project performs **customer segmentation** on the classic *Online Retail* dataset using the **RFM framework** (Recency, Frequency, Monetary) and **Kâ€‘Means clustering**. It includes outlier handling, feature scaling, elbow & silhouette analysis, and clear visualizations for segment interpretation.

> Built from the notebook: `Clustering and K-means.ipynb`

---

## âœ¨ What this project does

- Loads the *Online Retail* dataset (`Online_Retail.xlsx`).
- Cleans the data (drops null customer IDs, removes returns/cancellations and non-positive quantities/prices).
- Builds **RFM features** per customer:
  - **Recency** â€“ days since the last purchase
  - **Frequency** â€“ number of unique invoices
  - **Monetary** â€“ total spend (Quantity Ã— Price)
- Handles outliers with **IQR filtering** (separates outliers and nonâ€‘outliers).
- Scales features with **StandardScaler**.
- Determines **optimal `k`** via **Elbow (inertia)** and reports **Silhouette scores**.
- Fits **Kâ€‘Means** to nonâ€‘outliers (and separately to outliers), then **combines** results.
- Optionally maps numeric clusters to **humanâ€‘friendly segment names**.
- Produces helpful plots (boxplots, elbow curve, bar charts, 3D scatter) and exports `rfm_combined.csv`.

---

## ğŸ—‚ï¸ Repository structure 

```
.
â”œâ”€â”€ data/                # ( place dataset here)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Clustering and K-means.ipynb
â”œâ”€â”€ outputs/             # csv + figures generated
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## âš™ï¸ Setup

1. **Clone** this repository and move into it.
2. (Recommended) **Create a virtual environment**:
   ```bash
   python -m venv .venv
   # Windows
   .venv\Scripts\activate
   # macOS/Linux
   source .venv/bin/activate
   ```
3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
4. **Place the dataset** at `data/Online_Retail.xlsx` (or update the path in the notebook).

---

## â–¶ï¸ How to run

Open Jupyter and run the notebook topâ€‘toâ€‘bottom.

```bash
jupyter lab
# or
jupyter notebook
```

Key outputs youâ€™ll see:
- **Boxplot** of RFM features (to visualize spread and outliers).
- **Elbow curve** (inertia vs. number of clusters).
- **Silhouette scores** for `k=2..10`.
- **Kâ€‘Means** labels for nonâ€‘outliers and outliers (outlier clusters use negative labels).
- **3D scatter** and **bar charts** to interpret segments.
- Final CSV export: `outputs/rfm_combined.csv`.

---

## ğŸ§  Methodology 

- **RFM construction**
  - Snapshot date: one day after the max invoice date.
  - Group by `Customer ID` to compute `Recency`, `Frequency`, `Monetary`.
- **Outlier handling**
  - IQR rule per feature (1.5Ã—IQR beyond Q1/Q3).
  - Split into `rfm_non_outliers` and `rfm_outliers`.
- **Scaling**
  - Standardize features with `StandardScaler` before Kâ€‘Means.
- **Model selection**
  - Use **Elbow** for a visual knee point.
  - Print **Silhouette score** for added validation.
- **Clustering**
  - Fit Kâ€‘Means on nonâ€‘outliers (e.g., `k=4` per elbow).
  - Fit a separate Kâ€‘Means on outliers; assign **negative** labels (e.g., `-1..-4`) to keep them distinguishable.
  - Concatenate back into `rfm_combined`.
- **Segment naming (optional)**
  - Map numeric clusters to businessâ€‘friendly names in the notebook (e.g., â€œBig Playersâ€, â€œLoyalâ€, â€œAtâ€‘Riskâ€, â€œColdâ€, etc.).
  - The mapping depends on the cluster profiles (mean R/F/M per cluster).

---

## ğŸ” Interpreting clusters

Use the **cluster profile table** (mean Recency/Frequency/Monetary) to name clusters meaningfully. Typical patterns:
- **Low Recency (recent), High Frequency, High Monetary** â†’ Champions / Big Spenders
- **Moderate Recency, Moderate Frequency, Moderate Monetary** â†’ Good / Potential Loyalists
- **High Recency (stale), Low Frequency, Low Monetary** â†’ Cold / At Risk

Always verify with your actual means/counts from `cluster_profile`.

---

## ğŸ§ª Reproducibility

- Random seed fixed with `random_state=42` wherever Kâ€‘Means is used.
- Versions pinned in `requirements.txt` (see below).

---

## ğŸ“¦ Requirements

These libraries are used in the notebook:

- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`
- `seaborn`
- `openpyxl` (Excel reader/engine for `pandas.read_excel`)
- `jupyter` (to run the notebook)

Install via:
```bash
pip install -r requirements.txt
```

---

## ğŸ“ Dataset

This notebook expects the **Online Retail** dataset (`Online_Retail.xlsx`). If you donâ€™t want to commit the raw file, add it to `.gitignore` and provide a link or instructions for others to obtain it (e.g., from the UCI ML Repository).

---

## ğŸ¤ Contributing

Issues and PRs are welcome. Ideas to improve:
- Automate the notebook into a script/CLI.
- Add PCA for 2D visualization.
- Parameterize outlier strategy (IQR vs. zâ€‘score).
- Add tests and a Makefile for repeatable runs.

---

## ğŸ“œ License & Dataset Disclaimer

- This project is released for **educational and research purposes only**.  
- The dataset (`Online_Retail.xlsx`) is owned by its original provider (UCI Machine Learning Repository).  
- Please ensure you have rights to use the dataset before applying it in commercial or production settings.  
- The code in this repository is provided **as-is, without warranty**, under a permissive license of your choice (MIT recommended).  .

---

## ğŸ‘¤ Author

- **Harsha M Purohit** â€” feel free to connect or open an issue for questions.
